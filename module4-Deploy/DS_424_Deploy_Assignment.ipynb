{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Apply regularization techniques to your model. \n",
    "\n",
    "**Don't forget to switch to GPU on Colab!**\n",
    "\n",
    "\n",
    "## Objective \n",
    "\n",
    "In lecture, you were exposed to Lp space reguarlization, Max Norn weight constraints, and dropout. \n",
    "\n",
    "In this assignment, you will run several experiments in order to perform a deeper analysis on the effects that various regularization techniques have model performance and on the learned model weights. \n",
    "\n",
    "By the end of this assignment, these regularization techniques should no longer feel like black boxes to you (i.e. completely mysterious as to how they work.) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptJ2b3wk62Ud"
   },
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3499,
     "status": "ok",
     "timestamp": 1636134097802,
     "user": {
      "displayName": "Joseph catanzarite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64",
      "userId": "16649206137414945374"
     },
     "user_tz": 420
    },
    "id": "USXjs7Hk71Hy"
   },
   "outputs": [],
   "source": [
    "# native libraries \n",
    "import os\n",
    "from time import time \n",
    "\n",
    "# data analysis libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# deep learning libraries \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# regularizers \n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "# required for compatibility between sklearn and keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# native python unit test library\n",
    "from unittest import TestCase\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjhRTCFMBfF5"
   },
   "source": [
    "-----\n",
    "\n",
    "# $L_p$ Space Regularization \n",
    "\n",
    "## Bridging Theory and Practice \n",
    "\n",
    "Because the idea of infinitely many vector spaces, each with their very own distance metric for measuring distance differently can seem very abstract, we are going to take that distance metric general formula and look at a few special cases by writing custom regularization functions and taking note of their effect a the model's learning outcomes. \n",
    "\n",
    "Don't forget to review the theory of $L_p$ Space Regularization in the guided project. \n",
    "\n",
    "Also, watch this video if you haven't already. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qC4L1nb2BfF6"
   },
   "outputs": [],
   "source": [
    "# check out this video for an animated explaination of Lp Space and distance metrics \n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('FiSy6zWDfiA', width=800, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QH1qLDMBfF6"
   },
   "source": [
    "### Distance Metric General Formula\n",
    "$${\\displaystyle \\left\\|x\\right\\|_{p}=\\left(|x_{1}|^{p}+|x_{2}|^{p}+\\dotsb +|x_{n}|^{p}\\right)^{1/p}.}$$\n",
    "\n",
    "Let's create a class for the distance metric general formula.\n",
    "\n",
    "\n",
    "There are 2 classes below: \n",
    "\n",
    "```python\n",
    "class Test_distance_metric_solution()\n",
    "```\n",
    "\n",
    "You don't need to change anything in this class. This class is here in order to make sure that you calculate each portion of the distance metric general formula correctly. \n",
    "\n",
    "\n",
    "```python\n",
    "class Lp_distance_metric_general_formula()\n",
    "```\n",
    "\n",
    "This is the class that you will complete. \n",
    "\n",
    "Each of the non `__call__` methods calculate one portion of the distance metric general formula. \n",
    "\n",
    "Breaking up each portion of the formula into a separate method is actually unnecessary. \n",
    "\n",
    "Including the entire calculation of the general formula into a single method is ideal, however it is more difficult to write granular unit tests that way. \n",
    "\n",
    "So, for instructional purposes, it was broken up into 3 methods. However, outside of an academic environment, we would only need the `__init__` and `__call__` methods. \n",
    "\n",
    "Having said that, it is good for you to see how a custom unit test class is used to test the calculations of another class. This is a portion of what software engineering looks like. Get used to it. You'll need good software engineering practices to make it in the world. You'll learn more about this in your CS unit. For now, consider it a bit of foreshadowing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHjZxfINBfF8"
   },
   "outputs": [],
   "source": [
    "class Test_distance_metric_solution(TestCase):\n",
    "    \"\"\"\n",
    "    This is a unit test class desgined to make sure that the student calcualtes each component \n",
    "    of the Distance Metric General Formula correctly. Thereby getting real-time feedback and correction. \n",
    "    \"\"\"\n",
    "    \n",
    "    def test_squared_vector_comps(self, test_array):\n",
    "        \"\"\"\n",
    "        This test makes sure that student calculate the sum_of_squared_comp correctly. \n",
    "        \"\"\"\n",
    "        answer = np.array([1., 4.])\n",
    "        # error message in case if test case got failed\n",
    "        message = \"you did not calcualte sum_of_squared_comp correctly\"\n",
    "        # assert function() to check if values are almost equal\n",
    "        np.testing.assert_array_equal(answer, test_array,  err_msg=message)\n",
    "        \n",
    "        \n",
    "    def test_sum_of_squared_comp(self, test_sum):\n",
    "        \"\"\"\n",
    "        This test makes sure that student calculate the sum_of_squared_comp correctly. \n",
    "        \"\"\"\n",
    "        answer = 5\n",
    "        # error message in case if test case got failed\n",
    "        message = \"you did not calcualte sum_of_squared_comp correctly\"\n",
    "        # assert function() to check if values are almost equal\n",
    "        np.testing.assert_array_equal(answer, test_sum,  err_msg=message)\n",
    "        \n",
    "    def test_vector_norm(self, test_norm):\n",
    "        \"\"\"\n",
    "        This test makes sure that student calculate the vector_norm correctly. \n",
    "        \"\"\"\n",
    "        answer = 2.236\n",
    "        decimalPlace = 3\n",
    "        # error message in case if test case got failed\n",
    "        message = \"you did not calcualte sum_of_squared_comp correctly\"\n",
    "        # assert function() to check if values are almost equal\n",
    "        self.assertAlmostEqual(answer, test_norm,  decimalPlace, message)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJe9HDCQBfF8"
   },
   "source": [
    "### Fill in the missing code in the class below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "Sw8LiMThBfF9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8830110178a58a6fe1973906f649d36",
     "grade": false,
     "grade_id": "cell-0bd59a2d10fbf254",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Lp_distance_metric_general_formula(object):\n",
    "    \"\"\"\n",
    "    This class implements the Lp distance metric given an input p greater than or equal to 1\n",
    "    A user-specified regularization strength parameter reg_strength is used to scale the distance metric\n",
    "  \n",
    "    Example\n",
    "    -------\n",
    "    For p = 2, then the euclidean distance formula is derived.\n",
    "    For p = 1, then the \"taxicab\" distance formula is derived. \n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    It is possible to use p values less than 1 but those are special cases that we will ignore. \n",
    "    These special values are interesting for academic purposes but in practice you very likely won't need to know \n",
    "    about them.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=2, reg_strength = 1.0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        p: int or float\n",
    "            p value specifying the metric space in which the distance metric is to be calculalted\n",
    "            \n",
    "        reg_strength: int or float\n",
    "            usually set to a value less than 1.0 to decrease the strength of the distance metric when used as a model regularizer\n",
    "            keep this value at 1.0 when measureing vector norms (i.e. vector lengths)\n",
    "        \"\"\"\n",
    "        \n",
    "        assert p >=1 , \"p value must be greater than or equal to 1\"\n",
    "        \n",
    "        self.p = p\n",
    "        self.reg_strength = reg_strength\n",
    "                \n",
    "    def calc_squared_vector_comps(self):\n",
    "    \n",
    "        # raise each vector component in self.x to the power of p\n",
    "        # save result to self.squared_vector_comps\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def calc_sum_of_squared_comp(self):\n",
    "        # take the sum of the squared components in self.squared_vector_comps\n",
    "        # save to self.sum_of_squared_comp\n",
    "        # hint: use tf.reduce_sum\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def calc_vector_norm(self):\n",
    "        \n",
    "        # take the 1/p root of the self.sum_of_squared_comp in order to calculate the norm, i.e. ||x||\n",
    "        # save result to self.vector_norm\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        This method calculates the distance (i.e. norm) for vector x in Lp space for a user-specified value p\n",
    "        \n",
    "        ‖𝑥‖𝑝 = (|𝑥_1|^𝑝 + |𝑥_2|^𝑝 + ⋯ +|𝑥_𝑛|^𝑝 )^1/𝑝\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x: N-dimsional numpy array or tensorflow tensor of floats \n",
    "            x is our vector, could be a weight vector but any vector is valid \n",
    "            \n",
    "            \n",
    "        HINT\n",
    "        -----\n",
    "        You must use self.p when calculating squared_vector_comps and vector_norm\n",
    "        \"\"\"\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        # calculate the exponential terms |𝑥_i|^𝑝  in the sum\n",
    "        self.calc_squared_vector_comps()\n",
    "        \n",
    "        # calculate the sum of of the exponential terms  |𝑥_1|^𝑝 + |𝑥_2|^𝑝 + ⋯ +|𝑥_𝑛|^𝑝\n",
    "        self.calc_sum_of_squared_comp()\n",
    "        \n",
    "        # calculate the pth root of the sum of the exponential terms (|𝑥_1|^𝑝 + |𝑥_2|^𝑝 + ⋯ +|𝑥_𝑛|^𝑝 )^1/𝑝\n",
    "        self.calc_vector_norm()\n",
    "        \n",
    "        # return the vector norm scaled by a regularization penalty\n",
    "        # we say penalty because the value is usually less than 1.0 thereby scaling down the norm\n",
    "        return self.reg_strength * self.vector_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGo9fGgEBfF_"
   },
   "source": [
    "------\n",
    "### Unit Test your code\n",
    "\n",
    "You know you wrote your class correctly when all the unit tests pass. \n",
    "\n",
    "So the code in the following cell should run without throwing a single error. \n",
    "\n",
    "Protip: you can comment out 2nd and 3rd unit test in order to test your results for the first method and then uncomment as you go. Feel free to create a new cell and run your own testing there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Txd0urAoBfGA"
   },
   "outputs": [],
   "source": [
    "# instantiate the unit test class that will check the calculates of Lp_distance_metric_general_formula's methods\n",
    "tests = Test_distance_metric_solution()\n",
    "\n",
    "# instantiate Lp_distance_metric_general_formula, set p = 2 in order to derive the euclidean distance metric\n",
    "lp = Lp_distance_metric_general_formula( p=2, reg_strength = 1.0)\n",
    "\n",
    "# don't change this test_vector\n",
    "# Test_distance_metric_solution assumes that you're using ths exact test_vector\n",
    "test_vector = np.array([1., 2.])\n",
    "lp(test_vector)\n",
    "\n",
    "# test the calculations that are perform in each of the following lp class methods \n",
    "tests.test_squared_vector_comps(lp.squared_vector_comps)\n",
    "tests.test_sum_of_squared_comp(lp.sum_of_squared_comp)\n",
    "tests.test_vector_norm(lp.vector_norm.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILce8qBNBfGA"
   },
   "outputs": [],
   "source": [
    "# note: because we use tf.reduce_sum to calculate sum_of_squared_comp\n",
    "# the result is inside of a tensor and we need to use .numpy() to get the scalar out of the tensor \n",
    "print (lp.vector_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzVLWa43BfGB"
   },
   "outputs": [],
   "source": [
    "print (lp.vector_norm.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8J8KeKhBfGC"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dqiwzk6GBfGC"
   },
   "source": [
    "### Apply our $L_p$ Space Class\n",
    "\n",
    "Next we will use our distance metric class in order to calculate the euclidean and taxicab distance of our vector below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnJjVF0eBfGC"
   },
   "outputs": [],
   "source": [
    "# W is a 2D vector with an x and y component, i.e. (x, y) = (4,3)\n",
    "w = np.array([4., 3.])\n",
    "\n",
    "# origin point - we need to specify the starting point for plotting\n",
    "origin = np.array([0,0])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.arrow(origin[0], origin[1], w[0], w[1], head_width=0.5, head_length=0.7, fc='lightblue', ec='black')\n",
    "\n",
    "plt.grid()\n",
    "plt.yticks(np.arange(0,5))\n",
    "plt.xticks(np.arange(0,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jVHfYiwBfGC"
   },
   "source": [
    "## Derive Euclidean Distance from the General Formula \n",
    "\n",
    "This is the general formula for distance metrics. Where we have an $n$-dimensional weight vector **w**. Notice that the general formula has a vector component for each of the $n$ dimensions. Hence, it is the general formula.\n",
    "\n",
    "$${\\displaystyle \\left\\|\\textbf{w}\\right\\|_{p}=\\left(|w_{1}|^{p}+|w_{2}|^{p}+\\dotsb +|w_{n}|^{p}\\right)^{1/p}.}$$\n",
    " \n",
    "\n",
    "Let $n = 2$ such that our weight vector now exists in $2$ dimensional space. \n",
    "\n",
    "Let $p = 2$ such that our weight vector's distance will be calculated in $L_{p=2}$ space \n",
    "\n",
    "In which case our general formula gets reduced from $n$-dimensions to $2$-dimensions. So now we only need to consider a distance formula for a vector with $2$ components, one for each dimension.\n",
    "\n",
    "$$||\\textbf{w}||_{p=2} = ((x_2 - x_1)^2 + (y_2 - y_1)^2)^{1/2}$$\n",
    "\n",
    "Now just re-express the square root and we arrive at the familiar Euclidean Distance from high school algebra. \n",
    "\n",
    "$$||\\textbf{w}||_{p=2} = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$$\n",
    "\n",
    "\n",
    "You might be wondering about why the general case doesn't have differences for the components but the Euclidean Distance does explicitly show the component wise differences. It is common in mathematics to suppress certain information, especially if that information is \"obvious\" - however what is obvious is highly relative. \n",
    "\n",
    "The general formula assumes that the vector starts at the origin, in which case, there's no need to show the subtraction of zero from a vector component. \n",
    "\n",
    "Assuming that our vector starts at the origin (and it does) the formula can be reduced to \n",
    "\n",
    "$$||\\textbf{w}||_{p=2} = \\sqrt{(x_2 - 0)^2 + (y_2 - 0)^2}$$\n",
    "\n",
    "$$||\\textbf{w}||_{p=2} = \\sqrt{x_2^2 + y_2^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sgs-C39zBfGD"
   },
   "source": [
    "### Euclidean distance of our Vector \n",
    "\n",
    "With **p=2** in our `Lp_distance_metric_general_formula` class, we can calculate the euclidean distance of our vector **w**. You are encouraged to either solve the euclidean distance of our vector either in your head or on paper to prove to yourself that the above formula that we derived works and gives you `5` as an answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "Yp1V87DGBfGD",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf0cdea85e37c69f73956bf851cba8d6",
     "grade": false,
     "grade_id": "cell-74dae14f4bbad1ab",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zeVkMvtBfGD"
   },
   "source": [
    "-----\n",
    "\n",
    "## Derive Taxicab Distance from the General Formula \n",
    "\n",
    "This is the general formula for distance metrics. Where we have an N-dimensional weight vector **w**. Notice that the general formula has a vector component for each of the N dimensions. Hence, it is the general formula.\n",
    "\n",
    "$${\\displaystyle \\left\\|\\textbf{w}\\right\\|_{p}=\\left(|w_{1}|^{p}+|w_{2}|^{p}+\\dotsb +|w_{n}|^{p}\\right)^{1/p}.}$$\n",
    " \n",
    "\n",
    "Let N = 2 such that our weight vector now exists in 2 dimensional space. \n",
    "\n",
    "Let p = 1 such that our weight vector's distance will be calculated in $L_{p=1}$ space \n",
    "\n",
    "\n",
    "In which case our general formula gets reduced from N-dimensions to 2-dimensions. So now we only need to consider a distance formula for a vector with 2 components, one for each dimension.\n",
    "\n",
    "$$||\\textbf{w}||_{p=1} = ((x_2 - x_1)^1 + (y_2 - y_1)^1)^{1/1}$$\n",
    "\n",
    "There's no need to express all those 1's\n",
    "\n",
    "$$||\\textbf{w}||_{p=1} = (x_2 - x_1) + (y_2 - y_1) $$\n",
    "\n",
    "Assuming that our vector starts at the origin (which it does)\n",
    "\n",
    "$$||\\textbf{w}||_{p=1} = (x_2 - 0) + (y_2 - 0) $$\n",
    "\n",
    "\n",
    "\n",
    "$$||\\textbf{w}||_{p=1} = x + y $$\n",
    "\n",
    "We have just derived the Taxicab distance metric from the general formula. The above equation tells us to add up all the steps in the x and y direction in order to calculate the Taxicab distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bFZvxemBfGE"
   },
   "source": [
    "### Taxicab distance of our Vector \n",
    "\n",
    "With **p=1** in our `Lp_distance_metric_general_formula` class, we can calculate the taxicab distance of our vector **w**. This distance we can easily calculate in our head. Look at the plot of the vector and simply add up all the x and y components, i.e. count up all the steps you have to take in order to \"walk\" from the origin to the head of the vector. Do this to prove to yourself that the taxicab distance of our vector is `7`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "yDxY_PKgBfGE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a527c635255f30979d1759e4ecc480d",
     "grade": false,
     "grade_id": "cell-9bf41d7142ad35e9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# use Lp_distance_metric_general_formula class to calculate the taxicab distance of w\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZ8gfrk7BfGE"
   },
   "source": [
    "### Elastic Net Distance \n",
    "\n",
    "\n",
    "Elastic Net is a combination of L1 and L2. Compare the geometry below. \n",
    "\n",
    "![](https://ds100.org/sp17/assets/notebooks/linear_regression/norm_balls.png)\n",
    "\n",
    "The mathematical derivation of the distance metric for  $L_{p=3/2}$ space will be left to you as an optional exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "yM-pYUPmBfGF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f19be155b2e5be75c855710eab34cdd",
     "grade": false,
     "grade_id": "cell-d657c845dbb1ab23",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# use Lp_distance_metric_general_formula class to calculate the Elastic Net distance of w\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqDj4_XnBfGF"
   },
   "source": [
    "-----\n",
    "\n",
    "## Use Custom Lp Space class in modeling\n",
    "\n",
    "Let's create a function that returns compiled keras models so that we can run an experiment in order to compare the modeling results from using a keras L2 and our custom L2 regularizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfDpQTa4BfGP"
   },
   "source": [
    "-----\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgVhMGE9BfGP"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load in and normalize image data set\n",
    "    \"\"\"\n",
    "    \n",
    "    # load in our dataset \n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "    # normalize pixel values between 0 and 1 \n",
    "    max_pixel_value = X_train.max()\n",
    "    X_train, X_test = X_train /max_pixel_value , X_test / max_pixel_value\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P37ql8hCBfGQ"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDAeXnEVBfGQ"
   },
   "outputs": [],
   "source": [
    "# this is equal to the number of nodes in the output layer\n",
    "N_labels = len(np.unique(y_train))\n",
    "N_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-8-9L9HBfGQ"
   },
   "outputs": [],
   "source": [
    "def create_model(reg=None):\n",
    "    # instantiate Sequential class\n",
    "    model = Sequential([\n",
    "\n",
    "    # flatten images \n",
    "        Flatten(input_shape=(28,28)), # images will be flattend out to 784 dims row vectors \n",
    "\n",
    "    # hidden layer 1\n",
    "        Dense(500, kernel_regularizer=reg),\n",
    "\n",
    "    # act func 1\n",
    "        ReLU(negative_slope=0.01),\n",
    "\n",
    "    # output layer \n",
    "        Dense(10, activation =\"softmax\")   \n",
    "    ])\n",
    "\n",
    "    # compile model \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                  optimizer= \"adam\", \n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FrxA7iVBfGR"
   },
   "source": [
    "----\n",
    "\n",
    "## Experiment 1: Calculate vector lengths using Keras and Custom Regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXeF54VKBfGR"
   },
   "source": [
    "\n",
    "\n",
    "If you read the [**Keras Documentation**](https://keras.io/api/layers/regularizers/) for their implementation of L2 regularization you'll see this:\n",
    "\n",
    "    The L2 regularization penalty is computed as: loss = l2 * reduce_sum(square(x))\n",
    "    \n",
    "Notice that Keras isn't taking the square root for L2 where as we are take the square root.  Why? To save time. Minimizing the sum of the squares of the weights is mathematically the same problem as minimizing the square root of the sum of the squares of the weights. So why waste the extra processing time needed to compute that square root?\n",
    "\n",
    "In any case, We'll stay true to the math and take the square root for our implementation of L2 regularization. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgOVOYsYBfGR"
   },
   "outputs": [],
   "source": [
    "custom_l2 = Lp_distance_metric_general_formula(p=2, reg_strength = 1.0)\n",
    "# the length of the W vector from above as calcualted by the formula that we derived \n",
    "custom_l2(W).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSrL3SK0BfGS"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import L2\n",
    "keras_l2 = L2(l2=1.0)\n",
    "# again Keras doesn't take the square root\n",
    "keras_l2(W).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STf8O-3nBfGS"
   },
   "outputs": [],
   "source": [
    "# but if we take the square root, then we get the same answer that our custom regularizer class gives us \n",
    "np.sqrt(keras_l2(W).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWS0_EsJBfGS"
   },
   "source": [
    "----\n",
    "## Experiment 2: Compare Keras L2 and Custom L2 regularization in a model\n",
    "\n",
    "\n",
    "### Use Keras Built-in L2 regularizer \n",
    "\n",
    "Make sure to use the same regularization strength in the Keras pre-built L2 regularizer and in our custom L2 regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HI8OPnQMBfGT"
   },
   "outputs": [],
   "source": [
    "model_keras_l2 = create_model(reg=L2(l2=0.01))\n",
    "keras_l2_results = model_keras_l2.fit(X_train, y_train,\n",
    "                                      epochs=1,\n",
    "                                      validation_data=(X_test, y_test), \n",
    "                                      workers=10) # check! You might not be able to use 10 processors on your machine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_xMvRyGBfGT"
   },
   "source": [
    "### Use Custom Regularization Class \n",
    "\n",
    "Make sure to use the same regularization strength in the Keras pre-built L2 regularizer and in our custom L2 regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZB9FvIeBfGT"
   },
   "outputs": [],
   "source": [
    "# set p= 2 so that we are using the same L2 regularizer as above\n",
    "lp = Lp_distance_metric_general_formula(p=2, reg_strength = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFtWfFwYBfGT"
   },
   "outputs": [],
   "source": [
    "model_custom_l2 = create_model(reg=lp)\n",
    "custom_l2_results = model_custom_l2.fit(X_train, y_train,\n",
    "                                      epochs=1,\n",
    "                                      validation_data=(X_test, y_test), \n",
    "                                      workers=10) # check! You might not be able to use 10 processors on your machine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neZz88aoBfGT"
   },
   "source": [
    "----\n",
    "### Compare Model Results\n",
    "\n",
    "Let's compare the modeling results between the two models. \n",
    "\n",
    "Whatever the specific test accuracies are, it should be the case that using our custom class leads to slightly better results than using the Keras version of $L_2$ regularization.\n",
    "\n",
    "There a small difference between test accuracies, possible due to the random sampling for the initial weight values. But also possibly from the observation that we made above - Keras isn't taking the square root. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWk29B8bBfGU"
   },
   "outputs": [],
   "source": [
    "_, keras_acc = model_keras_l2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rwfQI8DBfGU"
   },
   "outputs": [],
   "source": [
    "_, custom_acc = model_custom_l2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpX3LEcHBfGU"
   },
   "source": [
    "\n",
    "### Conclusion \n",
    "\n",
    "In this experiment, we have bridged the gap between the theory of **$L_p$ Space Regularization** and the practice of using the general formula as a starting point to derive and build our very own regularizers. \n",
    "\n",
    "This experiment (and the Perceptron that we build from scratch in Sprint 2 Module 1) are examples of **mathematical algorithms** - an algorithm in mathematics is a procedure, a description of a set of steps that can be used to solve a mathematical computation.\n",
    "\n",
    "It's one thing to use open-source pre-built mathematical algorithms like Keras regularizers and Sklearn ML models but it's quite another thing to build them from scratch. \n",
    "\n",
    "In industry, you'll need to know when you should build something from scratch and when to use an open source solution. The rule of thumb is don't build it if someone else already has because maintaining the code and fixing bugs is something that other developers (ie. the open-source community) can spend their time on and you don't have to. But if an open source solution doesn't exist for a solution that you need, then you'll need to build it or try an alternative solution.\n",
    "\n",
    "It's good to get practice at building mathematical algorithms from scratch. It's a valuable skill to have. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDjNx1aVBfGU"
   },
   "source": [
    "-----\n",
    "# GridSearch Experiments \n",
    "\n",
    "The next set of experiments will all involve gridsearching regularization parameter values. \n",
    "\n",
    "The rest of the notebook will actually require very little coding on your part. Instead, the focus is for you to run those gridsearches and answer the questions at the end of each experiment. Those questions are designed to help you capture the insights that there are to learn from each of the experiments. \n",
    "\n",
    "All of the following experiments are designed to help you better understand the relationship between the various regularization techniques and how they affect model performance. \n",
    "\n",
    "\n",
    "### Build Model\n",
    "\n",
    "Let's build out the model that we'll be using all throughout our experiments. \n",
    "\n",
    "Remember that **the whole point of regularization is to prevent overfitting.**\n",
    "\n",
    "\n",
    "![](https://hackernoon.com/hn-images/1*vuZxFMi5fODz2OEcpG-S1g.png)\n",
    "\n",
    "Overfitting happens when our models are too complex, so in order to see a benefit from the use of regularization techniques we need to build a relatively complex model. \n",
    "\n",
    "Having said that, you might not have the computational resource to be able to train a complex model in a reasonable amount of time. So if this describes you, then you might want to consider using `build_simple_model`. Otherwise, use `build_complex_model`. \n",
    "\n",
    "In this notebook, we'll use  `build_complex_model` to run our experiments. \n",
    "\n",
    "**NOTE:** Whichever function you end up using to build a model, take time to read through the code and make sure you understand what is happening. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tdl9F-JtBfGU"
   },
   "outputs": [],
   "source": [
    "def build_complex_model(Lp_reg=None, reg_penalty=None, dropout_prob=0.0, maxnorm_wc=None):\n",
    "    \"\"\"\n",
    "    Build and return a regularized 3 hidden layer FCFF model \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Lp_reg: None or object\n",
    "        If object, Lp_reg is either l1 or l2 regularization \n",
    "        If None, that means that l1 or l2 regularization will not be used.\n",
    "     \n",
    "    reg_penalty: None or float\n",
    "        If float, reg_penalty is a value typically between 1.0 and 0.0001\n",
    "        This is the regularization strength for l1 or l2 \n",
    "        \n",
    "        \n",
    "    dropout_prob: float\n",
    "        This is the probability that dropout regularization will exclude a node from a training iteration. \n",
    "        If this value is 0.0, that means that dropout will not be used. \n",
    "        \n",
    "    maxnorm_wc: None or float\n",
    "        If float, maxnorm_wc is the weight constraint that is used for Max Norm regularization\n",
    "        If None, that means that Max Norm regularization will not be used.\n",
    "        \n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    model: compiled Keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    # if reg_type is not None, then pass in the penalty strength to whatever form of Lp space regularization this is \n",
    "    if Lp_reg is not None:\n",
    "        Lp_regularizer = Lp_reg(reg_penalty)\n",
    "    else:\n",
    "        Lp_regularizer = None\n",
    "                \n",
    "    if maxnorm_wc is not None:\n",
    "        wc = MaxNorm(max_value=maxnorm_wc)\n",
    "    else:\n",
    "        wc = None\n",
    "\n",
    "\n",
    "    # instantiate Sequential class\n",
    "    model = Sequential([\n",
    "\n",
    "    # flatten images \n",
    "    Flatten(input_shape=(28,28)),\n",
    "\n",
    "    # hidden layer 1\n",
    "    Dense(500, kernel_regularizer=Lp_regularizer , kernel_constraint=wc), # remember that Keras refers to weight matrix as a kernel, i.e. weights = kernel\n",
    "    # act func 1\n",
    "    ReLU(negative_slope=0.01),\n",
    "    Dropout(dropout_prob),\n",
    "\n",
    "    # hidden layer 2\n",
    "    Dense(250, kernel_regularizer=Lp_regularizer, kernel_constraint=wc),\n",
    "    # act func 2\n",
    "    ReLU(negative_slope=0.01),\n",
    "    Dropout(dropout_prob),\n",
    "\n",
    "    # hidden layer 3\n",
    "    Dense(100, kernel_regularizer=Lp_regularizer, kernel_constraint=wc),\n",
    "    # act func 2\n",
    "    ReLU(negative_slope=0.01),\n",
    "    Dropout(dropout_prob),\n",
    "\n",
    "    # output layer   \n",
    "    Dense(N_labels, activation=\"softmax\")  \n",
    "\n",
    "    ])\n",
    "    # compile model \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                 optimizer=\"adam\", \n",
    "                 metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tf7sg_qWBfGV"
   },
   "source": [
    "Again, only use `build_simple_model` instead of `build_complex_model` if you're working on a machine with very limited computational resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZDOyeFUBfGV"
   },
   "outputs": [],
   "source": [
    "# def build_simple_model(Lp_reg=None, reg_penalty=None, dropout_prob=0, maxnorm_wc=None):\n",
    "#     \"\"\"\n",
    "#     Build and return a regularized 1 hidden layer FCFF model \n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     Lp_reg: None or object\n",
    "#         If object, Lp_reg is either l1 or l2 regularization \n",
    "#         If None, that means that l1 or l2 regularization will not be used.\n",
    "     \n",
    "#     reg_penalty: None or float\n",
    "#         If float, reg_penalty is a value typically between 1.0 and 0.0001\n",
    "#         This is the regularization strength for l1 or l2 \n",
    "        \n",
    "        \n",
    "#     dropout_prob: float\n",
    "#         This is the probability that dropout regularization will exclude a node from a training iteration. \n",
    "#         If this value is 0.0, that means that dropout will not be used. \n",
    "        \n",
    "#     maxnorm_wc: None or float\n",
    "#         If float, maxnorm_wc is the weight constraint that is used for Max Norm regularization\n",
    "#         If None, that means that Max Norm regularization will not be used.\n",
    "        \n",
    "        \n",
    "#     Return\n",
    "#     ------\n",
    "#     model: compiled Keras model\n",
    "#     \"\"\"\n",
    "    \n",
    "#     if Lp_reg is not None:\n",
    "#         Lp_regularizer = Lp_reg(reg_penalty)\n",
    "#     else:\n",
    "#         Lp_regularizer = None\n",
    "\n",
    "#     # instantiate Sequential class\n",
    "#     model = Sequential([\n",
    "\n",
    "#     # flatten images \n",
    "#     Flatten(input_shape=(28,28)),\n",
    "\n",
    "#     # hidden layer 1\n",
    "#     Dense(128,  kernel_regularizer=Lp_regularizer, kernel_constraint=maxnorm_wc), # remember that Keras refers to weight matrix as a kernel, i.e. weights = kernel\n",
    "#     # act func 1\n",
    "#     ReLU(negative_slope=0.01),\n",
    "#     Dropout(p_dropout),\n",
    "\n",
    "#     # output layer   \n",
    "#     Dense(N_labels, activation=\"softmax\")  \n",
    "\n",
    "#     ])\n",
    "#     # compile model \n",
    "#     model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "#                  optimizer=\"adam\", \n",
    "#                  metrics=[\"accuracy\"])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIAKpcTEBfGW"
   },
   "source": [
    "Since we'll be using sklearn's `GridsearchCV` class, we need to wrap our Keras models in `KerasClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCOV1rcEBfGW"
   },
   "outputs": [],
   "source": [
    "# wrap KerasClassifier around build_model for compatibility with sklearn GridsearchCV \n",
    "model = KerasClassifier(build_fn = build_complex_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LJi-YVMBfGW"
   },
   "source": [
    "-------\n",
    "\n",
    "# Experiment 1: Identify the relationship between model performance and L2 penalty strength\n",
    "\n",
    "![](https://www.researchgate.net/publication/334159821/figure/fig1/AS:776025558495234@1562030319993/Ridge-regression-variable-selection.png)\n",
    "\n",
    "We are going to run a gridsearch solely on the L2 regularization penalty value and see the effect this has on model performance. \n",
    "\n",
    "By running a gridseach on only a single hyperparameter (while using the same data and model) we can isolate the effect of that hyperparameter. <br><br>\n",
    "_Note: <br>\n",
    "In the right panel of the above diagram, **SSE** <br>\n",
    "stands for \"Sum of Squared Errors\".<br>\n",
    "In the left panel, **ESS** is a typo that should read **SSE**._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxJ5Bc6HF2C0"
   },
   "outputs": [],
   "source": [
    "# build out our hyperparameter dictionary \n",
    "hyper_parameters = {\n",
    "    # take note that Lp_reg penalty/strength values are in powers of 10 \n",
    "    \"reg_penalty\": [1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001], \n",
    "    # Since we only want to test l2, provide l2 as the sole option \n",
    "    \"Lp_reg\": [l2],\n",
    "    # default is 1, in order to change it we must provide value here because we can't provide a parameter value for model.fit() directly when using gridsearch\n",
    "    # protip: consider chanign epochs to 1 if the gridsearche run-time are too long for you\n",
    "    \"epochs\": [1] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2fsK1TRBfGX"
   },
   "outputs": [],
   "source": [
    "start=time()\n",
    "# Create and run Grid Search\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=hyper_parameters, \n",
    "                    n_jobs=-3, \n",
    "                    verbose=1, \n",
    "                    cv=2)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "end=time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZb-QpxvBfGX"
   },
   "outputs": [],
   "source": [
    "print(\"Gridsearch runtime {0:.3} mins\".format( (end-start)/60 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FS1Vlh21BfGY"
   },
   "outputs": [],
   "source": [
    "# use the mean accuracy from the CV splits for determining best model score \n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "# move l2 penalty values outside of dictionary and into a list\n",
    "param_values = [dic[\"reg_penalty\"] for dic in params]\n",
    "\n",
    "# plot accuracy vs l2_reg_penalty\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.grid()\n",
    "\n",
    "# this plot is using the std of the CV splits to plot error bars however those values are so small that they aren't visable\n",
    "plt.errorbar(param_values, means, yerr=stds, ecolor=\"orange\")\n",
    "plt.xscale(\"log\") # use a log scale for ease of reading, recall that l2_reg_penalty were in powers of 10 \n",
    "plt.title(\"L2 Regularization: Model Accuracy vs L2 Penalty Strength\")\n",
    "plt.ylabel(\"Validation Accuracy\", )\n",
    "plt.xlabel(\"L2 Penalty Strength usng a Log Scale\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vc4hfY52BfGY"
   },
   "source": [
    "### Observations\n",
    "\n",
    "Write down some observations. What do you notice from the plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "G0Z92bfrBfGY",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "089b55b5a84d9c96c51fd341d9e6c74f",
     "grade": true,
     "grade_id": "cell-010212fc0915b976",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKoqryhBBfGZ"
   },
   "source": [
    "\n",
    "## Compare Weights between Best and Worst Model \n",
    "\n",
    "Next, we are going to compare the hidden layer weights between the best and worst performing model while taking note of the respective L2 penalty strengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Rb3l6GuBfGZ"
   },
   "outputs": [],
   "source": [
    "# get the best l2 penalty term \n",
    "best_lr_penalty = grid_result.best_params_[\"reg_penalty\"]\n",
    "\n",
    "# get the best trained model \n",
    "best_model = grid_result.best_estimator_.build_fn(Lp_reg=l2, reg_penalty=best_lr_penalty)\n",
    "\n",
    "# get the weights from the best trained model \n",
    "best_weights = best_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFxgfRA4BfGZ"
   },
   "outputs": [],
   "source": [
    "# train a model using the l2_reg_penalty value at scored the lowest \n",
    "worse_l2_reg_penalty = 1.0\n",
    "\n",
    "worse_model = build_complex_model(Lp_reg=l2, reg_penalty=worse_l2_reg_penalty)\n",
    "\n",
    "# fit model \n",
    "worse_model.fit(X_train, y_train, epochs=1)\n",
    "\n",
    "# get weights from worse performing model \n",
    "worse_weights = worse_model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJHi51iABfGZ"
   },
   "source": [
    "-----\n",
    "## Understanding how Weights and Biases are stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgo_lKxFBfGZ"
   },
   "source": [
    "Let's take a minute to understand that`.get_weights()` returns a list with 8 elements (if you're using `build_complex_model`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMdhtUWRBfGZ"
   },
   "outputs": [],
   "source": [
    "len(best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6raIvOpOBfGa"
   },
   "source": [
    "There are **weights matrices and bias vectors between each layer** and we have 5 layers. The last 4 layers are composed of neurons. \n",
    "\n",
    "- Input\n",
    "- Hidden 1\n",
    "- Hidden 2\n",
    "- Hidden 3\n",
    "- Output \n",
    "\n",
    "So we should have a weight matrix and a bias vector from each neuron layer, which accounts for $4 + 4 = 8$ elements in the list.\n",
    "\n",
    "\n",
    "#### Index for Weight Matrices \n",
    "If you index for a weight matrix, you can see its shape and that they are indeed matrices. \n",
    "\n",
    "Notice how you can see the dims of the layers that the matrices are sandwiched between?\n",
    "\n",
    "Input layer has 784 dims and hidden layer 1 has 500 dims. Given this understanding, the numbers you see in the shapes should make sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8Wmj_pjBfGa"
   },
   "outputs": [],
   "source": [
    "# bewteen input and 1st hidden layer\n",
    "best_weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRnY8DHHBfGa"
   },
   "outputs": [],
   "source": [
    "# bewteen 1st and 2nd hidden layer\n",
    "best_weights[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCQ-QZI4BfGb"
   },
   "outputs": [],
   "source": [
    "# bewteen 2nd and 3rd hidden layer\n",
    "best_weights[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiD6Ij2BBfGb"
   },
   "outputs": [],
   "source": [
    "# bewteen 3rd hidden layer and output layer\n",
    "best_weights[6].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9rAIBBuBfGb"
   },
   "source": [
    "#### Index for the bias vectors\n",
    "\n",
    "The shapes of the bias vectors should exactly match up the dims/nodes of each layer (excluding the input layer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5c97T5NBfGb"
   },
   "outputs": [],
   "source": [
    "# for hidden layer 1 \n",
    "best_weights[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWABwgJgBfGc"
   },
   "outputs": [],
   "source": [
    "# for hidden layer 2 \n",
    "best_weights[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juFKoCftBfGc"
   },
   "outputs": [],
   "source": [
    "# for hidden layer 3\n",
    "best_weights[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uul71OiBfGc"
   },
   "outputs": [],
   "source": [
    "# for output layer\n",
    "best_weights[7].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uwdFhiWBfGc"
   },
   "source": [
    "-----\n",
    "\n",
    "### Back to our Analysis of L2 space regularization (also known as Ridge)\n",
    "\n",
    "To gauge the performance effect of L2 regularization, we'll compare the weights for the 1st hidden layer from the best and worst performing models from our hyperparameter search space, as well as with the initial weight values that are randomly sampled from the GlorotUniform distribution.\n",
    "\n",
    "[**Check out the Keras docs for the Dense layer**](https://keras.io/api/layers/core_layers/dense/), you'll see that GlorotUniform is the default weight initializer. \n",
    "\n",
    "Read the docs to figure out how to get the weights from a Keras dense layer.\n",
    "Also have a look at this helpful post on StackOverflow: [**How to view initialized weights (i.e. before training)?**](https://stackoverflow.com/questions/46798708/how-to-view-initialized-weights-i-e-before-training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdmuttujBfGd"
   },
   "source": [
    "Before we compare weights, let's take note of the following. \n",
    "\n",
    "Both `best_weights[0]` or `worse_weights[0]` are matrices with shape `(784, 500)`. \n",
    "\n",
    "If we flatten them, then we get `784 * 500 = 392000` weights. What does this mean exactly?\n",
    "\n",
    "Remember that we are working with the Fully Connected Feed-Forward model which looks something like this. \n",
    "\n",
    "![](https://pyimagesearch.com/wp-content/uploads/2016/08/simple_neural_network_header.jpg)\n",
    "\n",
    "In Fully Connected neural network models, each output from a layer gets passed to all the nodes in next layer.<br>\n",
    "Our input layer has $784$ output weights which are the pixel values in the image. Each neuron (or node) in hidden layer $1$ also has $784$ weights, one for each pixel input.  Hidden layer 1 has $500$ neurons. So the weights are conveniently represented as a **weights matrix** with $784$ rows (one row for each pixel in the input image) and $500$ columns (one column for each neuron in the layer). The $i$th column of the weights matrix holds the $784$ weights $\\textbf{w}_{i}$ belonging to the $i$th neuron in the layer.\n",
    "\n",
    "To keep our analysis simple, we are going to analyze only the weights corresponding to the first neuron in hidden layer $1$, whose weights $\\textbf{w}_{1}$ are the first column of the weight matrix.  <br><br>\n",
    "\n",
    "We will observe the effect of L2 regularization on neuron 1 in hidden layer 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "xomeoSW4BfGd",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3f75126a80a74dd71fb0a9ab2b8b89f",
     "grade": false,
     "grade_id": "cell-7882876b8973bc7b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# index for the 1st column (784 entries) in the 1st hidden layer weights in best_weights and save to best_hidden_weights\n",
    "\n",
    "# index for the 1st column (784 entries) in the 1st hidden layer weights in worse_weights and save to worse_hidden_weights\n",
    "\n",
    "# Keras models randomly samples from the GlorotUniform distribution for the initial values of model weights \n",
    "# instantiate GlorotUniform and sample 784 weights and save to initial_weight_values\n",
    "\n",
    "# Build a data frame with these 3 vectors as columns\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaRHQzP2BfGe"
   },
   "outputs": [],
   "source": [
    "# move all weights to a dataframe for ease of analysis \n",
    "cols = [\"best_hidden_weights\", \"worse_hidden_weights\", \"initial_weight_values\"]\n",
    "data = [best_hidden_weights, worse_hidden_weights, initial_weight_values]\n",
    "df = pd.DataFrame(data=data).T\n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTxYblbIBfGe"
   },
   "outputs": [],
   "source": [
    "# check out the statistics for each weight column \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Np8LOGIBfGe"
   },
   "outputs": [],
   "source": [
    "# plot the distributions for each weight column \n",
    "df.hist(figsize=(20,12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAtwX9QfBfGe"
   },
   "source": [
    "## Observations \n",
    "\n",
    "Take a look at the statistical table and the plots. Then answer the following questions. \n",
    "\n",
    "**How do the hidden layer weights from the best performing model compare to the initial weight values?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "GcB8C891BfGe",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5eacb66f89b216ae3b4bb3c4b7bd6d38",
     "grade": true,
     "grade_id": "cell-6add7cc400c4c716",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ssnJofqBfGf"
   },
   "source": [
    "**What was the effect of using a small L2 penalty value (regularization constant)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "N3PyRkv_BfGf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92ac1689b72d727ab7f4d261c5e76daa",
     "grade": true,
     "grade_id": "cell-5b4f11bba2d49639",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dIM4qL5BfGf"
   },
   "source": [
    "**What was the effect of using a large L2 penalty value?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "yhaLO6-CBfGf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3048a6d2805f61d6fb58372c42c3ac54",
     "grade": true,
     "grade_id": "cell-0a30b62e5e119555",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rDYEPbsBfGg"
   },
   "source": [
    "**Given what you know about L2 regularization, are you surprised by these results?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "m3Nt5LmOBfGg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8a2034f67badfe53f601873f7026dc0",
     "grade": true,
     "grade_id": "cell-c04d067161064011",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SI5IBq8BfGg"
   },
   "source": [
    "----\n",
    "\n",
    "# Experiment 2: Identify the relationship between model performance and Max Norm Weight Constraint\n",
    "\n",
    "![](https://qph.fs.quoracdn.net/main-qimg-9d0dbf8074761b541ba80543ddfc9f73.webp)\n",
    "\n",
    "Recall from lecture that the **norm** of a vector is another word for the **length** of the vector.\n",
    "\n",
    "`MaxNorm` weight constraint puts a limit on the norm of the weight vector.\n",
    "\n",
    "The effect that Lp regularization and `MaxNorm` regularization have on the weights is similar, but they go about it in different ways. \n",
    "\n",
    "While Lp regularization (L1/Lasso and L2/Ridge) shrink the weight values by imposing constraints on their L1 and L2 norms, `MaxNorm` regularization shrinks the weight values by imposing a limit on the norm of a weight vector. Here's how it works: if an update would push the norm of a weight vector above MaxNorm, a scale factor is applied to all the weights so as to shrink the norm back to MaxNorm. \n",
    "\n",
    "In this experiment, we'll run another gridseach, similar to the one we ran for L2 regularization in the previous experiment. This time, we are going to gauge the effect of `MaxNorm` regularization on model performance and the distribution of the learned weights. As in the previous experiment, we will simplify our analysis by focusing on the weights for the first neuron in the first hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChP-sILzBfGg"
   },
   "source": [
    "Since we already built our model, we just need to update the `hyper_parameters` dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xdqcr6WBfGg"
   },
   "outputs": [],
   "source": [
    "# build out our hyperparameter dictionary \n",
    "hyper_parameters = {\n",
    "    \n",
    "    \"maxnorm_wc\": np.linspace(0.5, 10.0, num=20), \n",
    "    # default is 1, in order to change it we must provide value here because we can't provide a parameter value for model.fit() directly when using gridsearch\n",
    "    # protip: consider changing epochs to 1 if the gridsearche run-time are too long for you    \n",
    "    \"epochs\": [1] \n",
    "}\n",
    "\n",
    "hyper_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGQiKwo0BfGh"
   },
   "outputs": [],
   "source": [
    "start=time()\n",
    "# Create and run Grid Search\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=hyper_parameters, \n",
    "                    n_jobs=-2, \n",
    "                    verbose=1, \n",
    "                    cv=2)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "end=time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pslQN3T-BfGh"
   },
   "outputs": [],
   "source": [
    "print(\"Gridsearch runtime {0:.3} mins\".format( (end-start)/60 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxaAl3cvBfGh"
   },
   "outputs": [],
   "source": [
    "# use the mean accuracy from the CV splits for determining best model score \n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "\n",
    "# move l2 penalty values outside of dictionary and into a list\n",
    "param_values = [dic[\"maxnorm_wc\"] for dic in params]\n",
    "\n",
    "# plot accuracy vs l2_reg_penalty\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.grid()\n",
    "plt.errorbar(param_values, means, yerr=stds, ecolor=\"orange\")\n",
    "plt.title(\"L1 Regularization: Model Accuracy vs L1 Penalty Strength\")\n",
    "plt.ylabel(\"Validation Accuracy\", )\n",
    "plt.xlabel(\"Max Norm for Weight Vector \");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "D3aeaN_NBfGi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfe7bd54a7a14ba7ee63c88d6d1828b4",
     "grade": false,
     "grade_id": "cell-f67372e0b9b30614",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# get the best l2 penalty term from grid and save to best_max_norm_val\n",
    "\n",
    "# get the best trained model from grid and save to best_model\n",
    "\n",
    "# get the weights from the best trained model and save to best_weights\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udo9kxwWBfGi"
   },
   "outputs": [],
   "source": [
    "best_max_norm_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYdmRUJSBfGi"
   },
   "outputs": [],
   "source": [
    "# we see that the norm of our weights are indeed below the maximum allowed value \n",
    "np.linalg.norm(best_weights[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "3ew76uwZBfGi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67f65bd636e3b3b3bc7d20c02ba6b666",
     "grade": false,
     "grade_id": "cell-e752c1a8c853985d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train a model using the max_norm_val value that scored the lowest \n",
    "\n",
    "# build a model using build_complex_model and worse_max_norm_val and save it to worse_model\n",
    "\n",
    "# fit model \n",
    "\n",
    "# get weights from worse performing model \n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "DEx3m9vVBfGj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a38d5d4db707124b31a662fb4743b049",
     "grade": false,
     "grade_id": "cell-5c1aa4543e68487d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ck8kH2LeBfGk"
   },
   "outputs": [],
   "source": [
    "# move all weights to a dataframe for ease of analysis \n",
    "cols = [\"best_hidden_weights\", \"worse_hidden_weights\", \"initial_weight_values\"]\n",
    "data = [best_hidden_weights, worse_hidden_weights, initial_weight_values]\n",
    "df_maxnorm= pd.DataFrame(data=data).T\n",
    "df_maxnorm.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jiT661fNBfGk"
   },
   "outputs": [],
   "source": [
    "df_maxnorm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6HmKEFHBfGl"
   },
   "outputs": [],
   "source": [
    "# plot the distributions for each weight column \n",
    "df_maxnorm.hist(figsize=(20,12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJLb71QuBfGm"
   },
   "source": [
    "## Observations \n",
    "\n",
    "Take a look at the statistical table and the plots. Then answer the following questions. \n",
    "\n",
    "**How do the hidden layer weights from the best performing model compare to the initial weight values?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "9Ow24epzBfGm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f43fe1110cdcea8d1e4b432fe78d4e49",
     "grade": true,
     "grade_id": "cell-40a44d19694941b8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1C-q89taBfGm"
   },
   "source": [
    "**What was the effect of using the weight constraint value in MaxNorm in the best performing model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "JEnRcaxEBfGm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1c59c58a5abdbc0b509983821198dba",
     "grade": true,
     "grade_id": "cell-4f9e1e134124e512",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LY9joSwUBfGn"
   },
   "source": [
    "**What was the effect of using the weight constraint value in MaxNorm in the worse performing model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "8_Pw4Jb1BfGn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0062b4ddfad487c39633c37f4710b752",
     "grade": true,
     "grade_id": "cell-4c289ce70c34048a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWmTydgiBfGn"
   },
   "source": [
    "**Given what you know about MaxNorm regularization, are you surprised by these results?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "EiAQlNHuBfGn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c36931d3532a8cbcb4ea0c956378728",
     "grade": true,
     "grade_id": "cell-77366a912217da5d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_INtS2vBfGn"
   },
   "source": [
    "-----\n",
    "# Experiment 3: Identify the relationship between model performance and Dropout\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/max/981/1*EinUlWw1n8vbcLyT0zx4gw.png)\n",
    "\n",
    "In the 3rd and final experiment, we will use gridsearch to see how varying the value of the the dropout probability affects model performance. \n",
    "\n",
    "Recall from lecture that dropout tends to perform best when used with `MaxNorm` regularization. Since this is the case, we will gridsearch both dropout probability and the weight constraint for `MaxNorm`. \n",
    "\n",
    "If interested, feel free to read (or just skim) through the original publication on [**Drop Out**](https://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf). \n",
    "\n",
    "**Key Take aways:** \n",
    "\n",
    "1. During training, dropout will probabilistically \"turn off\" some neurons in the layer that dropout is implemented in. \n",
    "2. During inference (ie. making predictions on the test set) all neurons are used (i.e. no dropout is applied).\n",
    "3. Dropout works best when used with MaxNorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-CQiR-DBfGn"
   },
   "outputs": [],
   "source": [
    "# build out our hyperparameter dictionary \n",
    "hyper_parameters = {\n",
    "    # for the sake of runtime, let's vary maxnorm_wc between 0.5 and 5.0\n",
    "    \"maxnorm_wc\": np.linspace(0.5, 5, num=10),\n",
    "    # take note that l1_reg_penalty values are in powers of 10 \n",
    "    \"dropout_prob\": np.linspace(0.0, 0.6, num=7), \n",
    "    \"epochs\": [1] # default is 1, in order to change it we must provide value here because we can provide a parameter value for model.fit() directly when using gridsearch\n",
    "}\n",
    "\n",
    "hyper_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1M_xC_fBfGo"
   },
   "outputs": [],
   "source": [
    "start=time()\n",
    "# Create and run Grid Search\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=hyper_parameters, \n",
    "                    n_jobs=-2, \n",
    "                    verbose=1, \n",
    "                    cv=3)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "end=time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vg4ifWNtBfGo"
   },
   "outputs": [],
   "source": [
    "print(\"Gridsearch runtime {0:.3} mins\".format( (end-start)/60 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqO15wkmBfGo"
   },
   "outputs": [],
   "source": [
    "# use the mean accuracy from the CV splits for determining best model score \n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "\n",
    "# move l2 penalty values outside of dictionary and into a list\n",
    "param_values = [dic[\"dropout_prob\"] for dic in params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-v92GwGBfGo"
   },
   "source": [
    "Since there are 2 independent variables this time around (dropout_prob and maxnorm_wc) which affect the validation accuracy, it's best to use a different plot. A heat map will work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-W5UmNcBfGp"
   },
   "outputs": [],
   "source": [
    "dropout_prob_list = [  dic[\"dropout_prob\"]  for dic in params]\n",
    "maxnorm_wc_list = [  dic[\"maxnorm_wc\"]  for dic in params]\n",
    "data = [means, dropout_prob_list, maxnorm_wc_list ]\n",
    "\n",
    "cols = [\"val_acc\", \"dropout_prob\", \"maxnorm_wc\"]\n",
    "df_exp3 =pd.DataFrame(data=data).T\n",
    "df_exp3.columns = cols\n",
    "df_exp3.dropout_prob = df_exp3.dropout_prob.round(2)\n",
    "\n",
    "# pivot dataframe in preparation for heat map\n",
    "df_exp3 = df_exp3.pivot(\"maxnorm_wc\", \"dropout_prob\", \"val_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqilXbTYBfGp"
   },
   "outputs": [],
   "source": [
    "# Draw a heatmap with the val_acc values in each cell\n",
    "f, ax = plt.subplots(figsize=(18, 8))\n",
    "sns.heatmap(df_exp3, annot=True,  linewidths=.5, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dTgA0LEBfGp"
   },
   "source": [
    "### Observations \n",
    "\n",
    "We can see the dropout probabilities in the horizontal axis and the `MaxNorm` weight constraint values in the vertical axis. The values in the cells are the validation accuracy that corresponds to a pair of regularization values.\n",
    "\n",
    "Take a look at the heat map and answer the following questions. Note that depending on which model you used (the simple or complex one) your answers might be different from that of others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uz1meXeiBfGp"
   },
   "source": [
    "**What range of dropout probability values tend to produce the highest validation accuracy?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "xjxa3AaoBfGp",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f0013d4e07104a03b4d51664a308f53",
     "grade": true,
     "grade_id": "cell-4e0cb7a9240b1531",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiha7_G-BfGp"
   },
   "source": [
    "**What range of maxnorm weight constraints tend to produce the highest validation accuracy?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "ftoVpYqIBfGp",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fd88f0bb870a910b925d60b38d17694",
     "grade": true,
     "grade_id": "cell-99539755d7d328f7",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4M7ZARjJBfGp"
   },
   "source": [
    "**When taken together, what combinations of dropout probability and maxnorm weight constraints tend to produce the highest validation accuracy?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "rakqIiHNBfGq",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fee1e09ed8f6d354bd7b6e2986c2b811",
     "grade": true,
     "grade_id": "cell-5e19a56b4a2d975d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnwcQRx3BfGr"
   },
   "source": [
    "**Do you think that using dropout was helpful in increasing model performance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "mtdlzA8WBfGr",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de9c1bcff3c5eb6266cc80632d0956f0",
     "grade": true,
     "grade_id": "cell-d2a2f7b284c801dc",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQTmdo8nBfGr"
   },
   "source": [
    "-----\n",
    "# Stretch Goals for $L_p$ Space section\n",
    "\n",
    "Here are some ideas that you can explore using the custom distance metric class that you have built. Though if you think of something else, go for it!\n",
    "\n",
    "- Run a similar experiment but instead of comparing L2 between Keras and our custom class, compare L1 (Lasso) \n",
    "- Run a similar experiment but instead of comparing L2 between Keras and our custom class, compare L1_L2 (Elastic Net) \n",
    "- Run a gridsearch across several different Lp distance metrics and strengths and see which Lp distance leads to the best performing model\n",
    "    - Consider selecting a p range between **[1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, ..., 10]** step size of 0.5\n",
    "    - Consider selecting a p range between **[1, 10, 100, 1000, 10000]** step size in powers of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNmUwgIyBfGs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3qKJpF_BfGs"
   },
   "source": [
    "_____\n",
    "\n",
    "### Experiment 4: Train, Save, and Load a Keras model\n",
    "\n",
    "Let's get some practice with how to save and load trained Keras models \n",
    "\n",
    "For this experiment, review the section on Saving and Loading models from the guided project in order to help you to: \n",
    "\n",
    "- Build a model of your choosing\n",
    "- Gridsearch the model with a method of your choosing\n",
    "- Save the trained model to file\n",
    "- Load the trained model from file\n",
    "- Just as we did in the Guided Project, evalute the loaded model using a test set and make sure the results of the loaded model match that of the saved model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aki0LkDpBfGs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_424_Deploy_Assignment_fixed_typos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
